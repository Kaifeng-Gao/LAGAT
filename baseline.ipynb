{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, to_hetero\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch import nn\n",
    "from torch_geometric.utils import from_dgl\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.fraud_dataset as fraud_dataset\n",
    "\n",
    "DATASET_NAME = \"yelp\"\n",
    "TRAIN_SIZE = 0.4\n",
    "VAL_SIZE = 0.1\n",
    "RANDOM_SEED = 42\n",
    "FORCE_RELOAD = False\n",
    "\n",
    "EPOCHS = 1000\n",
    "TOLERATION = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method HeteroData.metadata of HeteroData(\n",
       "  review={\n",
       "    test_mask=[45954],\n",
       "    val_mask=[45954],\n",
       "    train_mask=[45954],\n",
       "    label=[45954],\n",
       "    feature=[45954, 32],\n",
       "  },\n",
       "  (review, net_rsr, review)={ edge_index=[2, 6805486] },\n",
       "  (review, net_rtr, review)={ edge_index=[2, 1147232] },\n",
       "  (review, net_rur, review)={ edge_index=[2, 98630] }\n",
       ")>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data = fraud_dataset.FraudDataset(\n",
    "    DATASET_NAME, \n",
    "    train_size=TRAIN_SIZE, \n",
    "    val_size=VAL_SIZE, \n",
    "    random_seed=RANDOM_SEED, \n",
    "    force_reload=FORCE_RELOAD\n",
    ")\n",
    "graph = fraud_data[0]\n",
    "\n",
    "data = from_dgl(graph)\n",
    "data.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=1, dropout=0.6):\n",
    "        super(GAT, self).__init__()\n",
    "        # First GAT convolution layer\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, concat=True, dropout=dropout, bias=False)\n",
    "        # Second GAT convolution layer\n",
    "        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=True, bias=False)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index))  # Apply the first GATConv layer\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)  # Apply the second GATConv layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name        target                                args                     kwargs\n",
      "-------------  ----------  ------------------------------------  -----------------------  ----------------------------------------------\n",
      "placeholder    x           x                                     ()                       {}\n",
      "placeholder    edge_index  edge_index                            ()                       {}\n",
      "call_function  dropout     <function dropout at 0x7fe1259c7d80>  (x,)                     {'p': 0.6, 'training': True, 'inplace': False}\n",
      "call_module    conv1       conv1                                 (dropout, edge_index)    {}\n",
      "call_function  elu         <function elu at 0x7fe1259d44a0>      (conv1,)                 {'alpha': 1.0, 'inplace': False}\n",
      "call_function  dropout_1   <function dropout at 0x7fe1259c7d80>  (elu,)                   {'p': 0.6, 'training': True, 'inplace': False}\n",
      "call_module    conv2       conv2                                 (dropout_1, edge_index)  {}\n",
      "output         output      output                                (conv2,)                 {}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x, edge_index):\n",
      "    dropout = torch.nn.functional.dropout(x, p = 0.6, training = True, inplace = False);  x = None\n",
      "    conv1 = self.conv1(dropout, edge_index);  dropout = None\n",
      "    elu = torch.nn.functional.elu(conv1, alpha = 1.0, inplace = False);  conv1 = None\n",
      "    dropout_1 = torch.nn.functional.dropout(elu, p = 0.6, training = True, inplace = False);  elu = None\n",
      "    conv2 = self.conv2(dropout_1, edge_index);  dropout_1 = edge_index = None\n",
      "    return conv2\n",
      "    \n",
      "opcode         name                                 target                                                  args                                                      kwargs\n",
      "-------------  -----------------------------------  ------------------------------------------------------  --------------------------------------------------------  ----------------------------------------------\n",
      "placeholder    x                                    x                                                       ()                                                        {}\n",
      "call_function  x_dict                               <function get_dict at 0x7fe0c8ab16c0>                   (x,)                                                      {}\n",
      "call_method    x__review                            get                                                     (x_dict, 'review', None)                                  {}\n",
      "placeholder    edge_index                           edge_index                                              ()                                                        {}\n",
      "call_function  edge_index_dict                      <function get_dict at 0x7fe0c8ab16c0>                   (edge_index,)                                             {}\n",
      "call_method    edge_index__review__net_rsr__review  get                                                     (edge_index_dict, ('review', 'net_rsr', 'review'), None)  {}\n",
      "call_method    edge_index__review__net_rtr__review  get                                                     (edge_index_dict, ('review', 'net_rtr', 'review'), None)  {}\n",
      "call_method    edge_index__review__net_rur__review  get                                                     (edge_index_dict, ('review', 'net_rur', 'review'), None)  {}\n",
      "call_function  dropout__review                      <function dropout at 0x7fe1259c7d80>                    (x__review,)                                              {'p': 0.6, 'training': True, 'inplace': False}\n",
      "call_module    conv1__review1                       conv1.review__net_rsr__review                           (dropout__review, edge_index__review__net_rsr__review)    {}\n",
      "call_module    conv1__review2                       conv1.review__net_rtr__review                           (dropout__review, edge_index__review__net_rtr__review)    {}\n",
      "call_module    conv1__review3                       conv1.review__net_rur__review                           (dropout__review, edge_index__review__net_rur__review)    {}\n",
      "call_function  conv1__review_1                      <built-in method add of type object at 0x7fe20fa655e0>  (conv1__review1, conv1__review2)                          {}\n",
      "call_function  conv1__review                        <built-in method add of type object at 0x7fe20fa655e0>  (conv1__review3, conv1__review_1)                         {}\n",
      "call_function  elu__review                          <function elu at 0x7fe1259d44a0>                        (conv1__review,)                                          {'alpha': 1.0, 'inplace': False}\n",
      "call_function  dropout_1__review                    <function dropout at 0x7fe1259c7d80>                    (elu__review,)                                            {'p': 0.6, 'training': True, 'inplace': False}\n",
      "call_module    conv2__review1                       conv2.review__net_rsr__review                           (dropout_1__review, edge_index__review__net_rsr__review)  {}\n",
      "call_module    conv2__review2                       conv2.review__net_rtr__review                           (dropout_1__review, edge_index__review__net_rtr__review)  {}\n",
      "call_module    conv2__review3                       conv2.review__net_rur__review                           (dropout_1__review, edge_index__review__net_rur__review)  {}\n",
      "call_function  conv2__review_1                      <built-in method add of type object at 0x7fe20fa655e0>  (conv2__review1, conv2__review2)                          {}\n",
      "call_function  conv2__review                        <built-in method add of type object at 0x7fe20fa655e0>  (conv2__review3, conv2__review_1)                         {}\n",
      "output         output                               output                                                  ({'review': conv2__review},)                              {}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x, edge_index):\n",
      "    x_dict = torch_geometric_nn_to_hetero_transformer_get_dict(x);  x = None\n",
      "    x__review = x_dict.get('review', None);  x_dict = None\n",
      "    edge_index_dict = torch_geometric_nn_to_hetero_transformer_get_dict(edge_index);  edge_index = None\n",
      "    edge_index__review__net_rsr__review = edge_index_dict.get(('review', 'net_rsr', 'review'), None)\n",
      "    edge_index__review__net_rtr__review = edge_index_dict.get(('review', 'net_rtr', 'review'), None)\n",
      "    edge_index__review__net_rur__review = edge_index_dict.get(('review', 'net_rur', 'review'), None);  edge_index_dict = None\n",
      "    dropout__review = torch.nn.functional.dropout(x__review, p = 0.6, training = True, inplace = False);  x__review = None\n",
      "    conv1__review1 = self.conv1.review__net_rsr__review(dropout__review, edge_index__review__net_rsr__review)\n",
      "    conv1__review2 = self.conv1.review__net_rtr__review(dropout__review, edge_index__review__net_rtr__review)\n",
      "    conv1__review3 = self.conv1.review__net_rur__review(dropout__review, edge_index__review__net_rur__review);  dropout__review = None\n",
      "    conv1__review_1 = torch.add(conv1__review1, conv1__review2);  conv1__review1 = conv1__review2 = None\n",
      "    conv1__review = torch.add(conv1__review3, conv1__review_1);  conv1__review3 = conv1__review_1 = None\n",
      "    elu__review = torch.nn.functional.elu(conv1__review, alpha = 1.0, inplace = False);  conv1__review = None\n",
      "    dropout_1__review = torch.nn.functional.dropout(elu__review, p = 0.6, training = True, inplace = False);  elu__review = None\n",
      "    conv2__review1 = self.conv2.review__net_rsr__review(dropout_1__review, edge_index__review__net_rsr__review);  edge_index__review__net_rsr__review = None\n",
      "    conv2__review2 = self.conv2.review__net_rtr__review(dropout_1__review, edge_index__review__net_rtr__review);  edge_index__review__net_rtr__review = None\n",
      "    conv2__review3 = self.conv2.review__net_rur__review(dropout_1__review, edge_index__review__net_rur__review);  dropout_1__review = edge_index__review__net_rur__review = None\n",
      "    conv2__review_1 = torch.add(conv2__review1, conv2__review2);  conv2__review1 = conv2__review2 = None\n",
      "    conv2__review = torch.add(conv2__review3, conv2__review_1);  conv2__review3 = conv2__review_1 = None\n",
      "    return {'review': conv2__review}\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaifeng/Documents/gnn_project/LAGAT/LAGAT/lib/python3.12/site-packages/torch_geometric/nn/fx.py:132: UserWarning: Found function 'dropout' with keyword argument 'training'. During FX tracing, this will likely be baked in as a constant value. Consider replacing this function by a module to properly encapsulate its training flag.\n",
      "  warnings.warn(f\"Found function '{node.name}' with keyword \"\n",
      "/home/kaifeng/Documents/gnn_project/LAGAT/LAGAT/lib/python3.12/site-packages/torch_geometric/nn/fx.py:132: UserWarning: Found function 'dropout_1' with keyword argument 'training'. During FX tracing, this will likely be baked in as a constant value. Consider replacing this function by a module to properly encapsulate its training flag.\n",
      "  warnings.warn(f\"Found function '{node.name}' with keyword \"\n"
     ]
    }
   ],
   "source": [
    "# from torch_geometric.nn.models import GAT\n",
    "\n",
    "# Creating a model instance covering heterogeneity\n",
    "# model = GAT(in_channels=32 ,hidden_channels=32, num_layers=2, out_channels=2)\n",
    "\n",
    "model = GAT(in_channels=32, hidden_channels=32, heads=2, out_channels=2)\n",
    "model = to_hetero(model, data.metadata(), aggr='sum', debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EarlyStopping]: Saving model to checkpoints/yelp/early_stop_20241117-144938.pth\n"
     ]
    }
   ],
   "source": [
    "from utils.earlystopping import EarlyStopping\n",
    "import time\n",
    "\n",
    "# Initialize early stopper\n",
    "early_stopper = EarlyStopping(dataset_name=DATASET_NAME, \n",
    "                             timestamp=time.strftime(\"%Y%m%d-%H%M%S\"),\n",
    "                             patience=TOLERATION)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "# Check if CUDA is available and set the device accordingly (GPU if available, else CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = \"cpu\"\n",
    "\n",
    "model = model.to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.feature_dict, data.edge_index_dict)\n",
    "\n",
    "    train_mask = data['review'].train_mask.to(device)\n",
    "    label = data['review'].label.to(device)\n",
    "\n",
    "    logits = out['review'][train_mask.bool()]\n",
    "    targets = label[train_mask.bool()].long()\n",
    "\n",
    "    loss = F.cross_entropy(logits, targets)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.feature_dict, data.edge_index_dict)\n",
    "        scores = torch.softmax(out['review'], dim=1)\n",
    "\n",
    "    labels = data['review'].label.cpu()\n",
    "    pred = scores.argmax(dim=1).cpu()\n",
    "    \n",
    "    # Calculate metrics for validation set\n",
    "    val_mask = data['review'].val_mask.cpu()\n",
    "    val_indices = val_mask.bool()\n",
    "    val_labels = labels[val_indices]\n",
    "    val_pred = pred[val_indices]\n",
    "    val_scores = scores[val_indices][:, 1].cpu()\n",
    "\n",
    "    # Calculate validation metrics\n",
    "    val_f1 = f1_score(val_labels, val_pred, average='macro')\n",
    "    try:\n",
    "        val_auc = roc_auc_score(val_labels, val_scores)\n",
    "        val_ap = average_precision_score(val_labels, val_scores)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning in validation metrics calculation: {e}\")\n",
    "        val_auc, val_ap = float('nan'), float('nan')\n",
    "\n",
    "    # Calculate validation loss\n",
    "    val_loss = F.cross_entropy(out['review'][val_indices].cpu(), \n",
    "                             data['review'].label[val_indices].cpu())\n",
    "    \n",
    "    return val_loss.item(), val_f1, val_auc, val_ap\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.feature_dict, data.edge_index_dict)\n",
    "        scores = torch.softmax(out['review'], dim=1)  # Convert logits to probabilities\n",
    "\n",
    "    labels = data['review'].label.cpu()\n",
    "    pred = scores.argmax(dim=1).cpu()\n",
    "\n",
    "    def calc_metrics(target_mask):\n",
    "        mask_indices = target_mask.cpu()\n",
    "        masked_labels = labels[mask_indices.bool()]\n",
    "        masked_pred = pred[mask_indices.bool()]\n",
    "        masked_scores = scores[mask_indices.bool()][:, 1].cpu()\n",
    "\n",
    "        f1 = f1_score(masked_labels, masked_pred, average='macro')\n",
    "        try:\n",
    "            auc = roc_auc_score(masked_labels, masked_scores)\n",
    "            ap = average_precision_score(masked_labels, masked_scores)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            auc, ap = float('nan'), float('nan')  # In case of an exception (like only one class present), return NaN\n",
    "        return f1, auc, ap\n",
    "\n",
    "    train_metrics = calc_metrics(data['review'].train_mask)\n",
    "    val_metrics = calc_metrics(data['review'].val_mask)\n",
    "    test_metrics = calc_metrics(data['review'].test_mask)\n",
    "\n",
    "    print('--- Training Metrics ---')\n",
    "    print(f'F1 Score: {train_metrics[0]:.4f}, AUC: {train_metrics[1]:.4f}, AP: {train_metrics[2]:.4f}')\n",
    "    \n",
    "    print('--- Validation Metrics ---')\n",
    "    print(f'F1 Score: {val_metrics[0]:.4f}, AUC: {val_metrics[1]:.4f}, AP: {val_metrics[2]:.4f}')\n",
    "    \n",
    "    print('--- Test Metrics ---')\n",
    "    print(f'F1 Score: {test_metrics[0]:.4f}, AUC: {test_metrics[1]:.4f}, AP: {test_metrics[2]:.4f}')\n",
    "\n",
    "    return {'train': train_metrics, 'val': val_metrics, 'test': test_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1000/1000 [02:31<00:00,  6.58it/s, Train Loss=0.3720, Val Loss=0.4162, Val F1=0.4629, Val AUC=0.7047, Val AP=0.2555, Best Val AP=0.3016]\n",
      "/home/kaifeng/Documents/gnn_project/LAGAT/utils/earlystopping.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(self.save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation AP: 0.3016 at epoch 896\n",
      "\n",
      "Final Evaluation:\n",
      "--- Training Metrics ---\n",
      "F1 Score: 0.4610, AUC: 0.7267, AP: 0.3017\n",
      "--- Validation Metrics ---\n",
      "F1 Score: 0.4628, AUC: 0.7237, AP: 0.2700\n",
      "--- Test Metrics ---\n",
      "F1 Score: 0.4615, AUC: 0.7285, AP: 0.2941\n"
     ]
    }
   ],
   "source": [
    "n_epochs = EPOCHS\n",
    "progress_bar = tqdm(range(n_epochs), desc='Training')\n",
    "\n",
    "for epoch in progress_bar:\n",
    "    # Training\n",
    "    train_loss = train()\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_f1, val_auc, val_ap = evaluate()\n",
    "    \n",
    "    # Use F1 score as the metric for early stopping\n",
    "    if early_stopper.step(epoch, val_loss, val_ap, model):\n",
    "        print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "        break\n",
    "    \n",
    "    # Update progress bar\n",
    "    progress_bar.set_postfix({\n",
    "        'Train Loss': f'{train_loss:.4f}',\n",
    "        'Val Loss': f'{val_loss:.4f}',\n",
    "        'Val F1': f'{val_f1:.4f}',\n",
    "        'Val AUC': f'{val_auc:.4f}',\n",
    "        'Val AP': f'{val_ap:.4f}',\n",
    "        'Best Val AP': f'{early_stopper.best_result:.4f}'\n",
    "    })\n",
    "\n",
    "# Load the best model\n",
    "early_stopper.load_checkpoint(model)\n",
    "print(f\"Best validation AP: {early_stopper.best_result:.4f} at epoch {early_stopper.best_epoch}\")\n",
    "\n",
    "# Final evaluation\n",
    "print(\"\\nFinal Evaluation:\")\n",
    "_ = test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is multi-step label leakage in training, might not learn anything, might learn something\n",
    "# This way can avoid using ego network (which cannot be run efficiently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAGAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
