{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, to_hetero\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch import nn\n",
    "from torch_geometric.utils import from_dgl\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)  # Or any other seed number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.fraud_dataset as fraud_dataset\n",
    "\n",
    "DATASET_NAME = \"yelp\"\n",
    "TRAIN_SIZE = 0.4\n",
    "VAL_SIZE = 0.1\n",
    "RANDOM_SEED = 42\n",
    "FORCE_RELOAD = False\n",
    "\n",
    "EPOCHS = 1000\n",
    "TOLERATION = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method HeteroData.metadata of HeteroData(\n",
       "  review={\n",
       "    test_mask=[45954],\n",
       "    val_mask=[45954],\n",
       "    train_mask=[45954],\n",
       "    label=[45954],\n",
       "    feature=[45954, 32],\n",
       "  },\n",
       "  (review, net_rsr, review)={ edge_index=[2, 6805486] },\n",
       "  (review, net_rtr, review)={ edge_index=[2, 1147232] },\n",
       "  (review, net_rur, review)={ edge_index=[2, 98630] }\n",
       ")>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data = fraud_dataset.FraudDataset(\n",
    "    DATASET_NAME, \n",
    "    train_size=TRAIN_SIZE, \n",
    "    val_size=VAL_SIZE, \n",
    "    random_seed=RANDOM_SEED, \n",
    "    force_reload=FORCE_RELOAD\n",
    ")\n",
    "graph = fraud_data[0]\n",
    "\n",
    "data = from_dgl(graph)\n",
    "data.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2384)\n",
      "tensor(0.0416)\n",
      "tensor(0.7200)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def mask_label(data, observed_pct=1):\n",
    "    # Ensure observed_pct is a value between 0 and 1\n",
    "    assert 0 <= observed_pct <= 1, \"observed_pct must be between 0 and 1\"\n",
    "    \n",
    "    # Create a copy of the labels to modify\n",
    "    label_mask = data[\"review\"].label.clone()\n",
    "    unknown_encoding = -1\n",
    "\n",
    "    # Mask all validation and test labels\n",
    "    label_mask[data[\"review\"].val_mask.bool()] = unknown_encoding\n",
    "    label_mask[data[\"review\"].test_mask.bool()] = unknown_encoding\n",
    "\n",
    "    # Identify the indices of the training data\n",
    "    train_indices = data[\"review\"].train_mask.nonzero(as_tuple=False).squeeze()\n",
    "\n",
    "    # Calculate the number of training labels to mask\n",
    "    num_train_labels = train_indices.size(0)\n",
    "    num_to_mask = int((1 - observed_pct) * num_train_labels)\n",
    "\n",
    "    # Randomly select indices to mask\n",
    "    mask_indices = train_indices[torch.randperm(num_train_labels)[:num_to_mask]]\n",
    "    label_mask[mask_indices] = unknown_encoding\n",
    "\n",
    "    return label_mask + 1\n",
    "\n",
    "# Example usage\n",
    "masked_labels = mask_label(data, 0.7)\n",
    "# Count the ratio of each label\n",
    "print((masked_labels == 1).float().mean())  # Prints the fraction of labels that are original class 0\n",
    "print((masked_labels == 2).float().mean())  # Prints the fraction of labels that are original class 1\n",
    "print((masked_labels == 0).float().mean())  # Prints the fraction of labels that are masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lagatconv import LAGATConv\n",
    "\n",
    "\n",
    "class GATWithLabels(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_labels, label_embedding_dim, heads=1, dropout=0.6):\n",
    "        super(GATWithLabels, self).__init__()\n",
    "        self.conv1 = LAGATConv(in_channels, hidden_channels, num_labels, label_embedding_dim, heads=heads, concat=True, dropout=dropout, bias=False)\n",
    "        self.conv2 = LAGATConv(hidden_channels * heads, out_channels, num_labels, label_embedding_dim, heads=1, concat=True, bias=False)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index, label_index):\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index, label_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index, label_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name         target                                args                                  kwargs\n",
      "-------------  -----------  ------------------------------------  ------------------------------------  ----------------------------------------------\n",
      "placeholder    x            x                                     ()                                    {}\n",
      "placeholder    edge_index   edge_index                            ()                                    {}\n",
      "placeholder    label_index  label_index                           ()                                    {}\n",
      "call_function  dropout      <function dropout at 0x7f0151ddbce0>  (x,)                                  {'p': 0.6, 'training': True, 'inplace': False}\n",
      "call_module    conv1        conv1                                 (dropout, edge_index, label_index)    {}\n",
      "call_function  elu          <function elu at 0x7f0151de8400>      (conv1,)                              {'alpha': 1.0, 'inplace': False}\n",
      "call_function  dropout_1    <function dropout at 0x7f0151ddbce0>  (elu,)                                {'p': 0.6, 'training': True, 'inplace': False}\n",
      "call_module    conv2        conv2                                 (dropout_1, edge_index, label_index)  {}\n",
      "output         output       output                                (conv2,)                              {}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x, edge_index, label_index):\n",
      "    dropout = torch.nn.functional.dropout(x, p = 0.6, training = True, inplace = False);  x = None\n",
      "    conv1 = self.conv1(dropout, edge_index, label_index);  dropout = None\n",
      "    elu = torch.nn.functional.elu(conv1, alpha = 1.0, inplace = False);  conv1 = None\n",
      "    dropout_1 = torch.nn.functional.dropout(elu, p = 0.6, training = True, inplace = False);  elu = None\n",
      "    conv2 = self.conv2(dropout_1, edge_index, label_index);  dropout_1 = edge_index = label_index = None\n",
      "    return conv2\n",
      "    \n",
      "opcode         name                                 target                                                  args                                                                           kwargs\n",
      "-------------  -----------------------------------  ------------------------------------------------------  -----------------------------------------------------------------------------  ----------------------------------------------\n",
      "placeholder    x                                    x                                                       ()                                                                             {}\n",
      "call_function  x_dict                               <function get_dict at 0x7f00806dd620>                   (x,)                                                                           {}\n",
      "call_method    x__review                            get                                                     (x_dict, 'review', None)                                                       {}\n",
      "placeholder    edge_index                           edge_index                                              ()                                                                             {}\n",
      "call_function  edge_index_dict                      <function get_dict at 0x7f00806dd620>                   (edge_index,)                                                                  {}\n",
      "call_method    edge_index__review__net_rsr__review  get                                                     (edge_index_dict, ('review', 'net_rsr', 'review'), None)                       {}\n",
      "call_method    edge_index__review__net_rtr__review  get                                                     (edge_index_dict, ('review', 'net_rtr', 'review'), None)                       {}\n",
      "call_method    edge_index__review__net_rur__review  get                                                     (edge_index_dict, ('review', 'net_rur', 'review'), None)                       {}\n",
      "placeholder    label_index                          label_index                                             ()                                                                             {}\n",
      "call_function  label_index_dict                     <function get_dict at 0x7f00806dd620>                   (label_index,)                                                                 {}\n",
      "call_method    label_index__review                  get                                                     (label_index_dict, 'review', None)                                             {}\n",
      "call_function  dropout__review                      <function dropout at 0x7f0151ddbce0>                    (x__review,)                                                                   {'p': 0.6, 'training': True, 'inplace': False}\n",
      "call_module    conv1__review1                       conv1.review__net_rsr__review                           (dropout__review, edge_index__review__net_rsr__review, label_index__review)    {}\n",
      "call_module    conv1__review2                       conv1.review__net_rtr__review                           (dropout__review, edge_index__review__net_rtr__review, label_index__review)    {}\n",
      "call_module    conv1__review3                       conv1.review__net_rur__review                           (dropout__review, edge_index__review__net_rur__review, label_index__review)    {}\n",
      "call_function  conv1__review_1                      <built-in method add of type object at 0x7f01cb6655e0>  (conv1__review1, conv1__review2)                                               {}\n",
      "call_function  conv1__review                        <built-in method add of type object at 0x7f01cb6655e0>  (conv1__review3, conv1__review_1)                                              {}\n",
      "call_function  elu__review                          <function elu at 0x7f0151de8400>                        (conv1__review,)                                                               {'alpha': 1.0, 'inplace': False}\n",
      "call_function  dropout_1__review                    <function dropout at 0x7f0151ddbce0>                    (elu__review,)                                                                 {'p': 0.6, 'training': True, 'inplace': False}\n",
      "call_module    conv2__review1                       conv2.review__net_rsr__review                           (dropout_1__review, edge_index__review__net_rsr__review, label_index__review)  {}\n",
      "call_module    conv2__review2                       conv2.review__net_rtr__review                           (dropout_1__review, edge_index__review__net_rtr__review, label_index__review)  {}\n",
      "call_module    conv2__review3                       conv2.review__net_rur__review                           (dropout_1__review, edge_index__review__net_rur__review, label_index__review)  {}\n",
      "call_function  conv2__review_1                      <built-in method add of type object at 0x7f01cb6655e0>  (conv2__review1, conv2__review2)                                               {}\n",
      "call_function  conv2__review                        <built-in method add of type object at 0x7f01cb6655e0>  (conv2__review3, conv2__review_1)                                              {}\n",
      "output         output                               output                                                  ({'review': conv2__review},)                                                   {}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x, edge_index, label_index):\n",
      "    x_dict = torch_geometric_nn_to_hetero_transformer_get_dict(x);  x = None\n",
      "    x__review = x_dict.get('review', None);  x_dict = None\n",
      "    edge_index_dict = torch_geometric_nn_to_hetero_transformer_get_dict(edge_index);  edge_index = None\n",
      "    edge_index__review__net_rsr__review = edge_index_dict.get(('review', 'net_rsr', 'review'), None)\n",
      "    edge_index__review__net_rtr__review = edge_index_dict.get(('review', 'net_rtr', 'review'), None)\n",
      "    edge_index__review__net_rur__review = edge_index_dict.get(('review', 'net_rur', 'review'), None);  edge_index_dict = None\n",
      "    label_index_dict = torch_geometric_nn_to_hetero_transformer_get_dict(label_index);  label_index = None\n",
      "    label_index__review = label_index_dict.get('review', None);  label_index_dict = None\n",
      "    dropout__review = torch.nn.functional.dropout(x__review, p = 0.6, training = True, inplace = False);  x__review = None\n",
      "    conv1__review1 = self.conv1.review__net_rsr__review(dropout__review, edge_index__review__net_rsr__review, label_index__review)\n",
      "    conv1__review2 = self.conv1.review__net_rtr__review(dropout__review, edge_index__review__net_rtr__review, label_index__review)\n",
      "    conv1__review3 = self.conv1.review__net_rur__review(dropout__review, edge_index__review__net_rur__review, label_index__review);  dropout__review = None\n",
      "    conv1__review_1 = torch.add(conv1__review1, conv1__review2);  conv1__review1 = conv1__review2 = None\n",
      "    conv1__review = torch.add(conv1__review3, conv1__review_1);  conv1__review3 = conv1__review_1 = None\n",
      "    elu__review = torch.nn.functional.elu(conv1__review, alpha = 1.0, inplace = False);  conv1__review = None\n",
      "    dropout_1__review = torch.nn.functional.dropout(elu__review, p = 0.6, training = True, inplace = False);  elu__review = None\n",
      "    conv2__review1 = self.conv2.review__net_rsr__review(dropout_1__review, edge_index__review__net_rsr__review, label_index__review);  edge_index__review__net_rsr__review = None\n",
      "    conv2__review2 = self.conv2.review__net_rtr__review(dropout_1__review, edge_index__review__net_rtr__review, label_index__review);  edge_index__review__net_rtr__review = None\n",
      "    conv2__review3 = self.conv2.review__net_rur__review(dropout_1__review, edge_index__review__net_rur__review, label_index__review);  dropout_1__review = edge_index__review__net_rur__review = label_index__review = None\n",
      "    conv2__review_1 = torch.add(conv2__review1, conv2__review2);  conv2__review1 = conv2__review2 = None\n",
      "    conv2__review = torch.add(conv2__review3, conv2__review_1);  conv2__review3 = conv2__review_1 = None\n",
      "    return {'review': conv2__review}\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaifeng/Documents/gnn_project/LAGAT/LAGAT/lib/python3.12/site-packages/torch_geometric/nn/fx.py:132: UserWarning: Found function 'dropout' with keyword argument 'training'. During FX tracing, this will likely be baked in as a constant value. Consider replacing this function by a module to properly encapsulate its training flag.\n",
      "  warnings.warn(f\"Found function '{node.name}' with keyword \"\n",
      "/home/kaifeng/Documents/gnn_project/LAGAT/LAGAT/lib/python3.12/site-packages/torch_geometric/nn/fx.py:132: UserWarning: Found function 'dropout_1' with keyword argument 'training'. During FX tracing, this will likely be baked in as a constant value. Consider replacing this function by a module to properly encapsulate its training flag.\n",
      "  warnings.warn(f\"Found function '{node.name}' with keyword \"\n"
     ]
    }
   ],
   "source": [
    "# Creating a model instance covering heterogeneity\n",
    "model = GATWithLabels(in_channels=32, hidden_channels=32, label_embedding_dim=32, num_labels=3, out_channels=2, heads=2)\n",
    "model = to_hetero(model, data.metadata(), aggr='sum', debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EarlyStopping]: Saving model to checkpoints/yelp/early_stop_20241117-145226.pth\n"
     ]
    }
   ],
   "source": [
    "from utils.earlystopping import EarlyStopping\n",
    "import time\n",
    "\n",
    "# Initialize early stopper\n",
    "early_stopper = EarlyStopping(dataset_name=DATASET_NAME, \n",
    "                             timestamp=time.strftime(\"%Y%m%d-%H%M%S\"),\n",
    "                             patience=TOLERATION)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "label_mask = {\"review\": masked_labels}\n",
    "\n",
    "# Check if CUDA is available and set the device accordingly (GPU if available, else CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = \"cpu\"\n",
    "\n",
    "model = model.to(device)\n",
    "data = data.to(device)\n",
    "label_mask = {key: value.to(device) for key, value in label_mask.items()}\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.feature_dict, data.edge_index_dict, label_mask)\n",
    "\n",
    "    train_mask = data['review'].train_mask.to(device)\n",
    "    label = data['review'].label.to(device)\n",
    "\n",
    "    logits = out['review'][train_mask.bool()]\n",
    "    targets = label[train_mask.bool()].long()\n",
    "\n",
    "    loss = F.cross_entropy(logits, targets)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.feature_dict, data.edge_index_dict, label_mask)\n",
    "        scores = torch.softmax(out['review'], dim=1)\n",
    "\n",
    "    labels = data['review'].label.cpu()\n",
    "    pred = scores.argmax(dim=1).cpu()\n",
    "    \n",
    "    # Calculate metrics for validation set\n",
    "    val_mask = data['review'].val_mask.cpu()\n",
    "    val_indices = val_mask.bool()\n",
    "    val_labels = labels[val_indices]\n",
    "    val_pred = pred[val_indices]\n",
    "    val_scores = scores[val_indices][:, 1].cpu()\n",
    "\n",
    "    # Calculate validation metrics\n",
    "    val_f1 = f1_score(val_labels, val_pred, average='macro')\n",
    "    try:\n",
    "        val_auc = roc_auc_score(val_labels, val_scores)\n",
    "        val_ap = average_precision_score(val_labels, val_scores)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning in validation metrics calculation: {e}\")\n",
    "        val_auc, val_ap = float('nan'), float('nan')\n",
    "\n",
    "    # Calculate validation loss\n",
    "    val_loss = F.cross_entropy(out['review'][val_indices].cpu(), \n",
    "                             data['review'].label[val_indices].cpu())\n",
    "    \n",
    "    return val_loss.item(), val_f1, val_auc, val_ap\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.feature_dict, data.edge_index_dict, label_mask)\n",
    "        scores = torch.softmax(out['review'], dim=1)  # Convert logits to probabilities\n",
    "\n",
    "    labels = data['review'].label.cpu()\n",
    "    pred = scores.argmax(dim=1).cpu()\n",
    "\n",
    "    def calc_metrics(target_mask):\n",
    "        mask_indices = target_mask.cpu()\n",
    "        masked_labels = labels[mask_indices.bool()]\n",
    "        masked_pred = pred[mask_indices.bool()]\n",
    "        masked_scores = scores[mask_indices.bool()][:, 1].cpu()\n",
    "\n",
    "        f1 = f1_score(masked_labels, masked_pred, average='macro')\n",
    "        try:\n",
    "            auc = roc_auc_score(masked_labels, masked_scores)\n",
    "            ap = average_precision_score(masked_labels, masked_scores)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            auc, ap = float('nan'), float('nan')  # In case of an exception (like only one class present), return NaN\n",
    "        return f1, auc, ap\n",
    "\n",
    "    train_metrics = calc_metrics(data['review'].train_mask)\n",
    "    val_metrics = calc_metrics(data['review'].val_mask)\n",
    "    test_metrics = calc_metrics(data['review'].test_mask)\n",
    "\n",
    "    print('--- Training Metrics ---')\n",
    "    print(f'F1 Score: {train_metrics[0]:.4f}, AUC: {train_metrics[1]:.4f}, AP: {train_metrics[2]:.4f}')\n",
    "    \n",
    "    print('--- Validation Metrics ---')\n",
    "    print(f'F1 Score: {val_metrics[0]:.4f}, AUC: {val_metrics[1]:.4f}, AP: {val_metrics[2]:.4f}')\n",
    "    \n",
    "    print('--- Test Metrics ---')\n",
    "    print(f'F1 Score: {test_metrics[0]:.4f}, AUC: {test_metrics[1]:.4f}, AP: {test_metrics[2]:.4f}')\n",
    "\n",
    "    return {'train': train_metrics, 'val': val_metrics, 'test': test_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1000/1000 [02:56<00:00,  5.66it/s, Train Loss=0.3694, Val Loss=0.4257, Val F1=0.4629, Val AUC=0.6966, Val AP=0.2534, Best Val AP=0.3069]\n",
      "/home/kaifeng/Documents/gnn_project/LAGAT/utils/earlystopping.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(self.save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation AP: 0.3069 at epoch 822\n",
      "\n",
      "Final Evaluation:\n",
      "--- Training Metrics ---\n",
      "F1 Score: 0.4602, AUC: 0.7251, AP: 0.3052\n",
      "--- Validation Metrics ---\n",
      "F1 Score: 0.4629, AUC: 0.7100, AP: 0.2518\n",
      "--- Test Metrics ---\n",
      "F1 Score: 0.4612, AUC: 0.7282, AP: 0.2961\n"
     ]
    }
   ],
   "source": [
    "n_epochs = EPOCHS\n",
    "progress_bar = tqdm(range(n_epochs), desc='Training')\n",
    "\n",
    "for epoch in progress_bar:\n",
    "    # Training\n",
    "    train_loss = train()\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_f1, val_auc, val_ap = evaluate()\n",
    "    \n",
    "    # Use F1 score as the metric for early stopping\n",
    "    if early_stopper.step(epoch, val_loss, val_ap, model):\n",
    "        print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "        break\n",
    "    \n",
    "    # Update progress bar\n",
    "    progress_bar.set_postfix({\n",
    "        'Train Loss': f'{train_loss:.4f}',\n",
    "        'Val Loss': f'{val_loss:.4f}',\n",
    "        'Val F1': f'{val_f1:.4f}',\n",
    "        'Val AUC': f'{val_auc:.4f}',\n",
    "        'Val AP': f'{val_ap:.4f}',\n",
    "        'Best Val AP': f'{early_stopper.best_result:.4f}'\n",
    "    })\n",
    "\n",
    "# Load the best model\n",
    "early_stopper.load_checkpoint(model)\n",
    "print(f\"Best validation AP: {early_stopper.best_result:.4f} at epoch {early_stopper.best_epoch}\")\n",
    "\n",
    "# Final evaluation\n",
    "print(\"\\nFinal Evaluation:\")\n",
    "_ = test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAGAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
